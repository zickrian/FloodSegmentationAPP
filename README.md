# ğŸŒŠ Flood Segmentation Web Application

Advanced flood area detection using deep learning (UNet & UNet++) with a modern web interface.

![Version](https://img.shields.io/badge/version-1.0.0-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![Python](https://img.shields.io/badge/python-3.11+-blue.svg)
![Next.js](https://img.shields.io/badge/next.js-15.1-black.svg)

## ğŸ¯ Features

- **Dual Model Analysis:** Compare UNet and UNet++ predictions
- **Interactive UI:** Modern, responsive design for desktop and mobile
- **Real-time Processing:** Get results in 1-3 seconds
- **Comprehensive Metrics:** Flood area percentage, pixel counts, and model agreement
- **Visual Overlays:** Color-coded segmentation masks
- **Disagreement Analysis:** See where models differ
- **Production Ready:** Deployed to Render with Docker

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Next.js   â”‚ â”€â”€â”€> â”‚   FastAPI   â”‚ â”€â”€â”€> â”‚  PyTorch    â”‚
â”‚  Frontend   â”‚      â”‚   Backend   â”‚      â”‚   Models    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Frontend:**
- Next.js 15 (App Router)
- React 18
- Tailwind CSS
- TypeScript

**Backend:**
- FastAPI
- PyTorch 2.1 (CPU)
- Segmentation Models PyTorch
- Pillow, NumPy, OpenCV-Headless

**Models:**
- UNet (ResNet34 encoder)
- UNet++ (ResNet34 encoder)
- Trained on flood segmentation dataset (290 images)
- Test IoU: 80.35% (UNet), 81.48% (UNet++)

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- Node.js 18+

### Local Development Setup

1. **Clone repository:**

```bash
git clone https://github.com/yourusername/flood-segmentation.git
cd flood-segmentation
```

2. **Setup Backend:**

```bash
cd backend

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run backend (models will be loaded from ../Models/)
uvicorn app.main:app --reload --port 8000
```

Backend will run on `http://localhost:8000`

3. **Setup Frontend:**

```bash
# In new terminal, from project root
npm install

# Create environment file
echo "NEXT_PUBLIC_API_URL=http://localhost:8000" > .env.local

# Run frontend
npm run dev
```

Frontend will run on `http://localhost:3000`

4. **Test:**

Open `http://localhost:3000` and upload a flood image!

## ğŸ“¦ Project Structure

```
flood-segmentation/
â”œâ”€â”€ app/                      # Next.js pages (App Router)
â”‚   â”œâ”€â”€ page.tsx             # Main upload page
â”‚   â”œâ”€â”€ layout.tsx           # Root layout
â”‚   â””â”€â”€ globals.css          # Global styles
â”œâ”€â”€ components/              # React components
â”‚   â”œâ”€â”€ UploadZone.tsx       # Drag & drop upload
â”‚   â”œâ”€â”€ ImagePreview.tsx     # Image preview
â”‚   â”œâ”€â”€ LoadingState.tsx     # Loading animation
â”‚   â”œâ”€â”€ ImageTabs.tsx        # Tabbed image viewer
â”‚   â”œâ”€â”€ AnalysisPanel.tsx    # Statistics & insights
â”‚   â””â”€â”€ ResultsViewer.tsx    # Complete results view
â”œâ”€â”€ lib/                     # Utilities
â”‚   â”œâ”€â”€ api.ts               # API client
â”‚   â”œâ”€â”€ types.ts             # TypeScript types
â”‚   â””â”€â”€ utils.ts             # Helper functions
â”œâ”€â”€ backend/                 # FastAPI backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py          # FastAPI app
â”‚   â”‚   â”œâ”€â”€ models.py        # Model loading
â”‚   â”‚   â”œâ”€â”€ preprocessing.py # Image preprocessing
â”‚   â”‚   â”œâ”€â”€ postprocessing.py# Analysis generation
â”‚   â”‚   â””â”€â”€ utils.py         # Helpers
â”‚   â”œâ”€â”€ Dockerfile           # Docker configuration for Render
â”‚   â””â”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ Models/                  # Pre-trained model weights
â”‚   â”œâ”€â”€ unet_baseline_best.pth
â”‚   â””â”€â”€ unetplus.pth
â”œâ”€â”€ render.yaml              # Render deployment configuration
â””â”€â”€ README.md               # This file
```

## ğŸš€ Deployment on Render

This application is configured for easy deployment to [Render](https://render.com) using Docker.

### Method 1: Blueprint (Recommended)

1. Fork/clone this repository to your GitHub account
2. Go to [Render Dashboard](https://dashboard.render.com)
3. Click **New +** â†’ **Blueprint**
4. Connect your GitHub repository
5. Render will auto-detect `render.yaml` and configure everything
6. Click **Apply** to deploy

### Method 2: Manual Web Service

1. Go to [Render Dashboard](https://dashboard.render.com)
2. Click **New +** â†’ **Web Service**
3. Connect your GitHub repository
4. Configure:
   - **Runtime:** Docker
   - **Docker Build Context:** `.` (root)
   - **Dockerfile Path:** `backend/Dockerfile`
5. Add environment variables:
   - `CORS_ORIGINS`: `*` (or your frontend URL)
   - `PYTHONUNBUFFERED`: `1`
6. Click **Deploy**

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `PORT` | Server port (auto-set by Render) | 8000 |
| `CORS_ORIGINS` | Allowed CORS origins | `*` |
| `PYTHONUNBUFFERED` | Python output buffering | `1` |
| `MODEL_PATH_UNET` | Custom UNet model path | `/Models/unet_baseline_best.pth` |
| `MODEL_PATH_UNETPP` | Custom UNet++ model path | `/Models/unetplus.pth` |

## ğŸ“Š Model Performance

From training on flood segmentation dataset:

| Model | Test IoU | Test Dice | Pixel Accuracy |
|-------|----------|-----------|----------------|
| UNet | 80.35% | 89.06% | 91.11% |
| UNet++ | 81.48% | 89.77% | 91.58% |

## ğŸ“ API Documentation

### Endpoints

#### Health Check
```http
GET /health
```

**Response:**
```json
{
  "status": "healthy",
  "models_loaded": true,
  "device": "cpu"
}
```

#### Segment Image
```http
POST /api/segment
Content-Type: multipart/form-data

Body:
  file: <image-file>
```

**Response:**
```json
{
  "success": true,
  "data": {
    "unet": {
      "flood_percent": 32.45,
      "flood_pixels": 21234,
      "total_pixels": 65536,
      "summary": "..."
    },
    "unetpp": { ... },
    "comparison": { ... },
    "images": {
      "original": "data:image/png;base64,...",
      "unet_overlay": "data:image/png;base64,...",
      "unetpp_overlay": "data:image/png;base64,...",
      "disagreement": "data:image/png;base64,..."
    }
  }
}
```

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [Segmentation Models PyTorch](https://github.com/qubvel/segmentation_models.pytorch)
- [FastAPI](https://fastapi.tiangolo.com/)
- [Next.js](https://nextjs.org/)
- [Flood Dataset](https://www.kaggle.com/datasets/faizalkarim/flood-area-segmentation)

---

**Built with â¤ï¸ using Next.js, FastAPI, and PyTorch**
